#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BizFin Pro SEO Pipeline v2 - –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞—Ç–µ–π

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç —Ä–µ–∞–ª–∏–∑—É–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω v2 —Å –ø–æ–ª–Ω–æ–π –ø—Ä–µ–µ–º—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é –¥–∞–Ω–Ω—ã—Ö
–∏ –ø–æ—Å—Ç-–ø—É–±–ª–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –∫–∞—á–µ—Å—Ç–≤–∞.

–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 14.10.2025
"""

import sys
import os
import json
import time
import logging
from datetime import datetime
from typing import Dict, Any, Optional, List
import argparse
from dataclasses import dataclass

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from config.database import DB_CONFIG
from config.wordpress import WordPressConfig, BizFinProBrand, ContentTemplates
from config.company_profile import CompanyData
from config.legal_compliance import ComplianceChecker
from modules.research.competitor_analyzer import CompetitorAnalyzer
from modules.alwrity_integration.alwrity_client import ALwrityClient
import mysql.connector
from mysql.connector import Error

@dataclass
class PipelineResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    keyword_id: int
    status: str
    message: str
    data: Dict[str, Any]
    execution_time: float
    errors: List[str]

class BizFinProPipeline:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –ø–∞–π–ø–ª–∞–π–Ω–∞ BizFin Pro"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        self.db_config = DB_CONFIG.get_config_dict()
        self.connection = None
        self.competitor_analyzer = CompetitorAnalyzer()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ALwrity –∫–ª–∏–µ–Ω—Ç–∞
        self.alwrity_client = ALwrityClient()
        
        # –ü—Ä–æ—Ñ–∏–ª—å –∫–æ–º–ø–∞–Ω–∏–∏
        self.company_data = CompanyData()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        self.stats = {
            'keywords_processed': 0,
            'articles_generated': 0,
            'articles_published': 0,
            'errors': 0,
            'start_time': None,
            'end_time': None
        }
    
    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        log_dir = os.path.join(os.path.dirname(__file__), '..', 'data', 'logs')
        os.makedirs(log_dir, exist_ok=True)
        
        log_file = os.path.join(log_dir, f'pipeline_v2_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
    
    def connect_database(self) -> bool:
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            self.connection = mysql.connector.connect(**self.db_config)
            self.connection.autocommit = False
            self.logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            return True
        except Error as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            return False
    
    def close_database(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        if self.connection and self.connection.is_connected():
            self.connection.close()
            self.logger.info("üîí –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∑–∞–∫—Ä—ã—Ç–æ")
    
    def add_keyword(self, keyword: str, **kwargs) -> Optional[int]:
        """
        –≠—Ç–∞–ø 0: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
        
        Args:
            keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            ID –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            cursor = self.connection.cursor()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
            cursor.execute("SELECT id FROM keywords WHERE keyword = %s", (keyword,))
            existing = cursor.fetchone()
            
            if existing:
                self.logger.warning(f"–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ '{keyword}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (ID: {existing[0]})")
                return existing[0]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
            insert_query = """
                INSERT INTO keywords (keyword, status, source, frequency, priority, target_volume, target_intent)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
            """
            
            values = (
                keyword,
                'pending',
                kwargs.get('source', 'manual'),
                kwargs.get('frequency', 1),
                kwargs.get('priority', 'medium'),
                kwargs.get('target_volume', 2500),
                kwargs.get('target_intent', 'informational')
            )
            
            cursor.execute(insert_query, values)
            keyword_id = cursor.lastrowid
            
            self.connection.commit()
            self.logger.info(f"‚úÖ –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ: '{keyword}' (ID: {keyword_id})")
            
            return keyword_id
            
        except Error as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞: {e}")
            self.connection.rollback()
            return None
        finally:
            if cursor:
                cursor.close()
    
    def analyze_competitors(self, keyword_id: int) -> Optional[int]:
        """
        –≠—Ç–∞–ø 1: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é ALwrity
        
        Args:
            keyword_id: ID –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
            
        Returns:
            ID –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            cursor = self.connection.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
            cursor.execute("SELECT keyword FROM keywords WHERE id = %s", (keyword_id,))
            result = cursor.fetchone()
            
            if not result:
                self.logger.error(f"–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ —Å ID {keyword_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                return None
            
            keyword = result[0]
            self.logger.info(f"üîç –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –¥–ª—è: '{keyword}'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–æ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
            if not ComplianceChecker.enforce_real_data_only():
                self.logger.error("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤")
                cursor.execute("UPDATE keywords SET status = 'error' WHERE id = %s", (keyword_id,))
                self.connection.commit()
                return None
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            cursor.execute("UPDATE keywords SET status = 'analyzing' WHERE id = %s", (keyword_id,))
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ ALwrity
            start_time = time.time()
            analysis_result = self.alwrity_client.research_competitors(keyword, num_results=3)
            analysis_duration = int(time.time() - start_time)
            
            if analysis_result['status'] != 'completed':
                self.logger.error(f"–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω: {analysis_result['status']}")
                cursor.execute("UPDATE keywords SET status = 'error' WHERE id = %s", (keyword_id,))
                self.connection.commit()
                return None
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
            insert_query = """
                INSERT INTO analysis (keyword_id, sources, structure, gaps, recommendations, 
                                    competitors_data, lsi_keywords, search_volume, competition_level, analysis_duration)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            
            values = (
                keyword_id,
                json.dumps([c.get('url', '') for c in analysis_result.get('competitors', [])]),
                json.dumps(analysis_result.get('content_structure', {})),
                json.dumps(analysis_result.get('gaps', [])),
                json.dumps(['–£–ª—É—á—à–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É', '–î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å']),
                json.dumps(analysis_result.get('competitors', [])),
                json.dumps(analysis_result.get('common_themes', [])),
                analysis_result.get('total_found', 0),
                'medium',
                analysis_duration
            )
            
            cursor.execute(insert_query, values)
            analysis_id = cursor.lastrowid
            
            self.connection.commit()
            self.logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω (ID: {analysis_id})")
            
            return analysis_id
            
        except Error as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {e}")
            self.connection.rollback()
            return None
        finally:
            if cursor:
                cursor.close()
    
    def generate_article(self, analysis_id: int) -> Optional[int]:
        """
        –≠—Ç–∞–ø 2: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ —Å –ø–æ–º–æ—â—å—é ALwrity
        
        Args:
            analysis_id: ID –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            ID —Å—Ç–∞—Ç—å–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            cursor = self.connection.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞
            cursor.execute("""
                SELECT a.*, k.keyword, k.target_volume, k.target_intent 
                FROM analysis a 
                JOIN keywords k ON a.keyword_id = k.id 
                WHERE a.id = %s
            """, (analysis_id,))
            
            result = cursor.fetchone()
            if not result:
                self.logger.error(f"–ê–Ω–∞–ª–∏–∑ —Å ID {analysis_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            keyword = result[1]  # k.keyword
            target_volume = result[2]  # k.target_volume
            competitors_data = json.loads(result[6])  # competitors_data
            
            self.logger.info(f"‚úçÔ∏è –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ –¥–ª—è: '{keyword}'")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç–∞—Ç—å—é —á–µ—Ä–µ–∑ ALwrity
            start_time = time.time()
            article_data = self.alwrity_client.generate_article(
                keyword=keyword,
                competitors_data={'competitors': competitors_data},
                company_profile=self.company_data.get_company_stats(),
                target_words=target_volume
            )
            generation_duration = int(time.time() - start_time)
            
            # SEO-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
            seo_optimized = self.alwrity_client.optimize_seo(article_data['content'], keyword)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è FAQ
            faq_data = self.alwrity_client.generate_faq(keyword, article_data['content'])
            
            # –°–æ–∑–¥–∞–µ–º HTML –≤–µ—Ä—Å–∏—é
            html_content = self._create_html_article(article_data, faq_data, keyword)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—å—é
            insert_query = """
                INSERT INTO articles (keyword_id, analysis_id, title, content_raw, html_raw, 
                                    word_count, reading_time, structure, lsi_keywords_used, generation_duration)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            
            values = (
                result[0],  # keyword_id
                analysis_id,
                article_data['title'],
                article_data['content'],
                html_content,
                article_data.get('word_count', len(article_data['content'].split())),
                article_data.get('reading_time', 12),
                json.dumps(article_data.get('structure', [])),
                json.dumps(article_data.get('lsi_keywords_used', [])),
                generation_duration
            )
            
            cursor.execute(insert_query, values)
            article_id = cursor.lastrowid
            
            self.connection.commit()
            self.logger.info(f"‚úÖ –°—Ç–∞—Ç—å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ (ID: {article_id})")
            
            return article_id
            
        except Error as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏: {e}")
            self.connection.rollback()
            return None
        finally:
            if cursor:
                cursor.close()
    
    def _create_html_article(self, article_data: Dict[str, Any], faq_data: Dict[str, Any], keyword: str) -> str:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ HTML –≤–µ—Ä—Å–∏–∏ —Å—Ç–∞—Ç—å–∏ –≤ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–º —Å—Ç–∏–ª–µ BizFin Pro
        
        Args:
            article_data: –î–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
            faq_data: –î–∞–Ω–Ω—ã–µ FAQ
            keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
            
        Returns:
            HTML –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç–∞—Ç—å–∏
        """
        from config.design_system import DesignGenerator
        
        design = DesignGenerator()
        css_styles = design.generate_css_styles()
        
        html = f"""
        <style>
        {css_styles}
        </style>
        
        <article class="bizfin-article">
            <header class="article-header">
                <h1 class="bizfin-h1">{article_data['title']}</h1>
                <p class="article-meta">–ü–æ–ª—É—á–∏—Ç–µ {keyword} –±—ã—Å—Ç—Ä–æ –∏ –≤—ã–≥–æ–¥–Ω–æ! –≠–∫—Å–ø–µ—Ä—Ç–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ —Å –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–æ–º, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º –±–∞–Ω–∫–æ–≤ –∏ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∫–µ–π—Å–∞–º–∏.</p>
            </header>
            
            <div class="bizfin-section">
                <div class="article-content">
                    {article_data['content']}
                </div>
            </div>
            
            <div class="bizfin-section">
                <h2 class="bizfin-h2">–ß–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã</h2>
                {faq_data.get('html', '')}
            </div>
            
            <div class="bizfin-section">
                <div class="bizfin-highlight">
                    <h3 class="bizfin-h3">üöÄ –ì–æ—Ç–æ–≤—ã –ø–æ–ª—É—á–∏—Ç—å {keyword}?</h3>
                    <p>–ù–∞—à–∏ —ç–∫—Å–ø–µ—Ä—Ç—ã –ø–æ–º–æ–≥—É—Ç –≤–∞–º —Å—ç–∫–æ–Ω–æ–º–∏—Ç—å –≤—Ä–µ–º—è, –¥–µ–Ω—å–≥–∏ –∏ –Ω–µ—Ä–≤—ã –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ {keyword}</p>
                    <button class="bizfin-cta-button">üìû –ü–æ–ª—É—á–∏—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é</button>
                </div>
            </div>
            
            <footer class="article-footer">
                <div class="bizfin-card">
                    <h3>–û –∫–æ–º–ø–∞–Ω–∏–∏ –ë–∏–∑–Ω–µ—Å –§–∏–Ω–∞–Ω—Å</h3>
                    <p>{self.company_data.get_company_intro()}</p>
                    <p><strong>–ö–æ–Ω—Ç–∞–∫—Ç—ã:</strong> {self.company_data.get_contact_info()['phone']}</p>
                </div>
            </footer>
        </article>
        """
        
        return html
    
    def _generate_article_content(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç–∞—Ç—å–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        
        –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å AI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        """
        keyword = analysis_data['keyword']
        target_volume = analysis_data['target_volume']
        lsi_keywords = analysis_data['lsi_keywords'][:10]  # –¢–æ–ø-10 LSI –∫–ª—é—á–µ–π
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        title = f"{keyword}: –ø–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –ø–æ–ª—É—á–µ–Ω–∏—é –≤ 2024 –≥–æ–¥—É"
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç–∞—Ç—å–∏
        structure = {
            'sections': [
                '–í–≤–µ–¥–µ–Ω–∏–µ',
                '–ß—Ç–æ —Ç–∞–∫–æ–µ ' + keyword,
                '–í–∏–¥—ã –∏ —Ç–∏–ø—ã',
                '–°—Ç–æ–∏–º–æ—Å—Ç—å –∏ —Ä–∞—Å—á–µ—Ç',
                '–î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è',
                '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∞–Ω–∫–æ–≤',
                '–†–µ–∞–ª—å–Ω—ã–π –∫–µ–π—Å —É—Å–ø–µ—Ö–∞',
                '–ß–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã',
                '–ó–∞–∫–ª—é—á–µ–Ω–∏–µ'
            ],
            'word_count_target': target_volume,
            'lsi_keywords_planned': lsi_keywords
        }
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (–∑–∞–≥–ª—É—à–∫–∞)
        content_raw = f"""
# {title}

## –í–≤–µ–¥–µ–Ω–∏–µ

{keyword} ‚Äî —ç—Ç–æ –≤–∞–∂–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞. –í –¥–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã –ø–æ–ª—É—á–µ–Ω–∏—è {keyword} –≤ 2024 –≥–æ–¥—É.

## –ß—Ç–æ —Ç–∞–∫–æ–µ {keyword}

{keyword} –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π...

## –í–∏–¥—ã –∏ —Ç–∏–ø—ã

–°—É—â–µ—Å—Ç–≤—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∏–¥–æ–≤ {keyword}:

1. –û—Å–Ω–æ–≤–Ω–æ–π –≤–∏–¥
2. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –≤–∏–¥
3. –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –≤–∏–¥

## –°—Ç–æ–∏–º–æ—Å—Ç—å –∏ —Ä–∞—Å—á–µ—Ç

–°—Ç–æ–∏–º–æ—Å—Ç—å {keyword} –∑–∞–≤–∏—Å–∏—Ç –æ—Ç...

## –î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è

–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è {keyword} –ø–æ—Ç—Ä–µ–±—É—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:

- –î–æ–∫—É–º–µ–Ω—Ç 1
- –î–æ–∫—É–º–µ–Ω—Ç 2
- –î–æ–∫—É–º–µ–Ω—Ç 3

## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∞–Ω–∫–æ–≤

| –ë–∞–Ω–∫ | –ö–æ–º–∏—Å—Å–∏—è | –°—Ä–æ–∫ | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ |
|------|----------|------|-------------|
| –ë–∞–Ω–∫ 1 | 2% | 3 –¥–Ω—è | –ë—ã—Å—Ç—Ä–æ–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ |
| –ë–∞–Ω–∫ 2 | 2.5% | 5 –¥–Ω–µ–π | –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ |

## –†–µ–∞–ª—å–Ω—ã–π –∫–µ–π—Å —É—Å–ø–µ—Ö–∞

–ö–æ–º–ø–∞–Ω–∏—è "–ü—Ä–∏–º–µ—Ä" –ø–æ–ª—É—á–∏–ª–∞ {keyword} –∑–∞ 3 –¥–Ω—è...

## –ß–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã

### –ö–∞–∫ –±—ã—Å—Ç—Ä–æ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å {keyword}?

–°—Ä–æ–∫–∏ –ø–æ–ª—É—á–µ–Ω–∏—è {keyword} —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç...

### –°–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç {keyword}?

–°—Ç–æ–∏–º–æ—Å—Ç—å {keyword} –≤–∞—Ä—å–∏—Ä—É–µ—Ç—Å—è...

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

{keyword} ‚Äî —ç—Ç–æ –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–±...

**–ì–æ—Ç–æ–≤—ã –ø–æ–ª—É—á–∏—Ç—å {keyword}? –°–≤—è–∂–∏—Ç–µ—Å—å —Å –Ω–∞—à–∏–º–∏ —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏!**
        """.strip()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML –≤–µ—Ä—Å–∏—é
        html_raw = f"""
        <article>
            <h1>{title}</h1>
            <div class="content">
                {content_raw.replace('#', '<h2>').replace('##', '</h2><h3>').replace('###', '</h3><h4>')}
            </div>
        </article>
        """
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–ª–æ–≤–∞
        word_count = len(content_raw.split())
        reading_time = max(1, word_count // 200)  # 200 —Å–ª–æ–≤ –≤ –º–∏–Ω—É—Ç—É
        
        return {
            'title': title,
            'content_raw': content_raw,
            'html_raw': html_raw,
            'word_count': word_count,
            'reading_time': reading_time,
            'structure': structure,
            'lsi_keywords_used': lsi_keywords
        }
    
    def run_full_pipeline(self, keyword: str, **kwargs) -> PipelineResult:
        """
        –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ v2
        
        Args:
            keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
        """
        start_time = time.time()
        errors = []
        
        try:
            self.logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ v2 –¥–ª—è –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞: '{keyword}'")
            self.stats['start_time'] = datetime.now()
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
            if not self.connect_database():
                return PipelineResult(
                    keyword_id=0,
                    status='error',
                    message='–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö',
                    data={},
                    execution_time=time.time() - start_time,
                    errors=['Database connection failed']
                )
            
            # –≠—Ç–∞–ø 0: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
            keyword_id = self.add_keyword(keyword, **kwargs)
            if not keyword_id:
                errors.append('Failed to add keyword')
                return PipelineResult(
                    keyword_id=0,
                    status='error',
                    message='–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ',
                    data={},
                    execution_time=time.time() - start_time,
                    errors=errors
                )
            
            # –≠—Ç–∞–ø 1: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
            analysis_id = self.analyze_competitors(keyword_id)
            if not analysis_id:
                errors.append('Failed to analyze competitors')
                return PipelineResult(
                    keyword_id=keyword_id,
                    status='error',
                    message='–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤',
                    data={'keyword_id': keyword_id},
                    execution_time=time.time() - start_time,
                    errors=errors
                )
            
            # –≠—Ç–∞–ø 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏
            article_id = self.generate_article(analysis_id)
            if not article_id:
                errors.append('Failed to generate article')
                return PipelineResult(
                    keyword_id=keyword_id,
                    status='error',
                    message='–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç—å—é',
                    data={'keyword_id': keyword_id, 'analysis_id': analysis_id},
                    execution_time=time.time() - start_time,
                    errors=errors
                )
            
            # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ —ç—Ç–∞–ø—ã –ø–∞–π–ø–ª–∞–π–Ω–∞
            # –≠—Ç–∞–ø 3: SEO-–ø—Ä–æ–≤–µ—Ä–∫–∞
            # –≠—Ç–∞–ø 4: –£–ª—É—á—à–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏
            # –≠—Ç–∞–ø 5: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ EEC
            # –≠—Ç–∞–ø 6: –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ WordPress
            # –≠—Ç–∞–ø 7: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
            # –≠—Ç–∞–ø 8: –§–∏–∫—Å–∞—Ü–∏—è SEO-–º–µ—Ç–∞
            # –≠—Ç–∞–ø 9: –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è WordPress
            # –≠—Ç–∞–ø 10: –§–∏–Ω–∞–ª—å–Ω—ã–π –∞—É–¥–∏—Ç
            
            self.stats['keywords_processed'] += 1
            self.stats['articles_generated'] += 1
            
            execution_time = time.time() - start_time
            self.stats['end_time'] = datetime.now()
            
            self.logger.info(f"‚úÖ –ü–∞–π–ø–ª–∞–π–Ω v2 –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {execution_time:.2f} —Å–µ–∫—É–Ω–¥")
            
            return PipelineResult(
                keyword_id=keyword_id,
                status='completed',
                message='–ü–∞–π–ø–ª–∞–π–Ω v2 —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω',
                data={
                    'keyword_id': keyword_id,
                    'analysis_id': analysis_id,
                    'article_id': article_id,
                    'execution_time': execution_time
                },
                execution_time=execution_time,
                errors=errors
            )
            
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞: {e}")
            errors.append(str(e))
            self.stats['errors'] += 1
            
            return PipelineResult(
                keyword_id=0,
                status='error',
                message=f'–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}',
                data={},
                execution_time=time.time() - start_time,
                errors=errors
            )
        
        finally:
            self.close_database()
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        return self.stats.copy()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='BizFin Pro SEO Pipeline v2')
    parser.add_argument('--keyword', required=True, help='–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞')
    parser.add_argument('--priority', default='medium', choices=['low', 'medium', 'high', 'urgent'], help='–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç')
    parser.add_argument('--target-volume', type=int, default=2500, help='–¶–µ–ª–µ–≤–æ–π –æ–±—ä–µ–º —Å—Ç–∞—Ç—å–∏')
    parser.add_argument('--intent', default='informational', choices=['informational', 'commercial', 'educational', 'faq', 'review'], help='–¢–∏–ø –∏–Ω—Ç–µ–Ω—Ç–∞')
    parser.add_argument('--verbose', '-v', action='store_true', help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
    pipeline = BizFinProPipeline()
    
    result = pipeline.run_full_pipeline(
        keyword=args.keyword,
        priority=args.priority,
        target_volume=args.target_volume,
        target_intent=args.intent
    )
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print(f"\n{'='*60}")
    print(f"–†–ï–ó–£–õ–¨–¢–ê–¢ –í–´–ü–û–õ–ù–ï–ù–ò–Ø –ü–ê–ô–ü–õ–ê–ô–ù–ê V2")
    print(f"{'='*60}")
    print(f"–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ: {args.keyword}")
    print(f"–°—Ç–∞—Ç—É—Å: {result.status}")
    print(f"–°–æ–æ–±—â–µ–Ω–∏–µ: {result.message}")
    print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result.execution_time:.2f} —Å–µ–∫—É–Ω–¥")
    
    if result.errors:
        print(f"–û—à–∏–±–∫–∏: {', '.join(result.errors)}")
    
    if result.data:
        print(f"–î–∞–Ω–Ω—ã–µ: {json.dumps(result.data, indent=2, ensure_ascii=False)}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = pipeline.get_statistics()
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {stats['keywords_processed']}")
    print(f"- –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Å—Ç–∞—Ç–µ–π: {stats['articles_generated']}")
    print(f"- –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ —Å—Ç–∞—Ç–µ–π: {stats['articles_published']}")
    print(f"- –û—à–∏–±–æ–∫: {stats['errors']}")
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
    sys.exit(0 if result.status == 'completed' else 1)

if __name__ == "__main__":
    main()
