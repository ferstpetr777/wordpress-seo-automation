#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è BizFin Pro SEO Pipeline v2
"""

import sys
import os
import sqlite3
import json
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from config.database_sqlite import DB_CONFIG
from modules.research.competitor_analyzer import CompetitorAnalyzer

def create_sqlite_database():
    """–°–æ–∑–¥–∞–Ω–∏–µ SQLite –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üóÑÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ SQLite –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    
    config = DB_CONFIG.get_config_dict()
    db_path = config['database']
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    os.makedirs(os.path.dirname(db_path), exist_ok=True)
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # –°–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS keywords (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            keyword TEXT NOT NULL UNIQUE,
            date_added DATETIME DEFAULT CURRENT_TIMESTAMP,
            status TEXT DEFAULT 'pending',
            source TEXT DEFAULT 'manual',
            frequency INTEGER DEFAULT 1,
            user_id INTEGER DEFAULT 1,
            priority TEXT DEFAULT 'medium',
            target_volume INTEGER DEFAULT 2500,
            target_intent TEXT DEFAULT 'informational',
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS analysis (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            keyword_id INTEGER NOT NULL,
            sources TEXT, -- JSON
            structure TEXT, -- JSON
            gaps TEXT, -- JSON
            recommendations TEXT, -- JSON
            competitors_data TEXT, -- JSON
            lsi_keywords TEXT, -- JSON
            search_volume INTEGER,
            competition_level TEXT DEFAULT 'medium',
            date_created DATETIME DEFAULT CURRENT_TIMESTAMP,
            analysis_duration INTEGER,
            FOREIGN KEY (keyword_id) REFERENCES keywords(id)
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS articles (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            keyword_id INTEGER NOT NULL,
            analysis_id INTEGER NOT NULL,
            title TEXT NOT NULL,
            content_raw TEXT NOT NULL,
            html_raw TEXT NOT NULL,
            word_count INTEGER DEFAULT 0,
            reading_time INTEGER DEFAULT 0,
            structure TEXT, -- JSON
            lsi_keywords_used TEXT, -- JSON
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            generation_duration INTEGER,
            FOREIGN KEY (keyword_id) REFERENCES keywords(id),
            FOREIGN KEY (analysis_id) REFERENCES analysis(id)
        )
    ''')
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_keywords_status ON keywords(status)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_analysis_keyword_id ON analysis(keyword_id)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_articles_keyword_id ON articles(keyword_id)')
    
    conn.commit()
    conn.close()
    
    print(f"‚úÖ SQLite –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω–∞: {db_path}")
    return db_path

def test_competitor_analyzer():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"""
    print("\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤...")
    
    analyzer = CompetitorAnalyzer(max_competitors=2, delay=0.5)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å –ø—Ä–æ—Å—Ç—ã–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º
    keyword = "–±–∞–Ω–∫–æ–≤—Å–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è"
    print(f"–ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞: '{keyword}'")
    
    try:
        result = analyzer.analyze_keyword(keyword)
        
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º: {result['status']}")
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {len(result.get('competitors', []))}")
        
        if result.get('competitors'):
            print("üèÜ –¢–æ–ø –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã:")
            for i, competitor in enumerate(result['competitors'][:3], 1):
                print(f"   {i}. {competitor['domain']} - {competitor['word_count']} —Å–ª–æ–≤")
        
        if result.get('lsi_keywords'):
            print(f"üîë LSI –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(result['lsi_keywords'][:5])}")
        
        if result.get('gaps'):
            print(f"‚ö†Ô∏è –í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã: {', '.join(result['gaps'][:3])}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return None

def test_database_operations():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–π —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüíæ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–π —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö...")
    
    config = DB_CONFIG.get_config_dict()
    db_path = config['database']
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    try:
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
        cursor.execute('''
            INSERT OR IGNORE INTO keywords (keyword, status, priority, target_volume)
            VALUES (?, ?, ?, ?)
        ''', ('—Ç–µ—Å—Ç–æ–≤–∞—è –±–∞–Ω–∫–æ–≤—Å–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è', 'pending', 'medium', 2500))
        
        keyword_id = cursor.lastrowid
        if keyword_id == 0:
            # –ü–æ–ª—É—á–∞–µ–º ID —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
            cursor.execute('SELECT id FROM keywords WHERE keyword = ?', ('—Ç–µ—Å—Ç–æ–≤–∞—è –±–∞–Ω–∫–æ–≤—Å–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è',))
            keyword_id = cursor.fetchone()[0]
        
        print(f"‚úÖ –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ/–Ω–∞–π–¥–µ–Ω–æ (ID: {keyword_id})")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        test_analysis = {
            'sources': ['https://example1.com', 'https://example2.com'],
            'structure': {'avg_word_count': 2500, 'avg_images': 5},
            'gaps': ['–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ FAQ', '–°–ª–∞–±—ã–µ CTA'],
            'recommendations': ['–î–æ–±–∞–≤–∏—Ç—å FAQ', '–£–ª—É—á—à–∏—Ç—å CTA'],
            'competitors_data': [{'url': 'https://example1.com', 'word_count': 2000}],
            'lsi_keywords': ['–≥–∞—Ä–∞–Ω—Ç–∏—è', '–±–∞–Ω–∫', '–∫—Ä–µ–¥–∏—Ç']
        }
        
        cursor.execute('''
            INSERT INTO analysis (keyword_id, sources, structure, gaps, recommendations, 
                                competitors_data, lsi_keywords, search_volume, analysis_duration)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            keyword_id,
            json.dumps(test_analysis['sources']),
            json.dumps(test_analysis['structure']),
            json.dumps(test_analysis['gaps']),
            json.dumps(test_analysis['recommendations']),
            json.dumps(test_analysis['competitors_data']),
            json.dumps(test_analysis['lsi_keywords']),
            1000,
            30
        ))
        
        analysis_id = cursor.lastrowid
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –¥–æ–±–∞–≤–ª–µ–Ω (ID: {analysis_id})")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ç–∞—Ç—å—é
        test_article = {
            'title': '–¢–µ—Å—Ç–æ–≤–∞—è –±–∞–Ω–∫–æ–≤—Å–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è: –ø–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ',
            'content_raw': '–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–∞—è —Å—Ç–∞—Ç—å—è –æ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –≥–∞—Ä–∞–Ω—Ç–∏—è—Ö...',
            'html_raw': '<h1>–¢–µ—Å—Ç–æ–≤–∞—è –±–∞–Ω–∫–æ–≤—Å–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è</h1><p>–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–∞—è —Å—Ç–∞—Ç—å—è...</p>',
            'word_count': 2500,
            'reading_time': 12,
            'structure': {'sections': ['–í–≤–µ–¥–µ–Ω–∏–µ', '–û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å', '–ó–∞–∫–ª—é—á–µ–Ω–∏–µ']},
            'lsi_keywords_used': ['–≥–∞—Ä–∞–Ω—Ç–∏—è', '–±–∞–Ω–∫', '–∫—Ä–µ–¥–∏—Ç']
        }
        
        cursor.execute('''
            INSERT INTO articles (keyword_id, analysis_id, title, content_raw, html_raw,
                                word_count, reading_time, structure, lsi_keywords_used, generation_duration)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            keyword_id,
            analysis_id,
            test_article['title'],
            test_article['content_raw'],
            test_article['html_raw'],
            test_article['word_count'],
            test_article['reading_time'],
            json.dumps(test_article['structure']),
            json.dumps(test_article['lsi_keywords_used']),
            60
        ))
        
        article_id = cursor.lastrowid
        print(f"‚úÖ –°—Ç–∞—Ç—å—è –¥–æ–±–∞–≤–ª–µ–Ω–∞ (ID: {article_id})")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
        cursor.execute('''
            SELECT k.keyword, a.competitors_data, ar.title, ar.word_count
            FROM keywords k
            JOIN analysis a ON k.id = a.keyword_id
            JOIN articles ar ON a.id = ar.analysis_id
            WHERE k.id = ?
        ''', (keyword_id,))
        
        result = cursor.fetchone()
        if result:
            print(f"‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö:")
            print(f"   –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ: {result[0]}")
            print(f"   –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {len(json.loads(result[1]))}")
            print(f"   –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏: {result[2]}")
            print(f"   –°–ª–æ–≤ –≤ —Å—Ç–∞—Ç—å–µ: {result[3]}")
        
        conn.commit()
        print("‚úÖ –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø–µ—Ä–∞—Ü–∏–π —Å –ë–î: {e}")
        conn.rollback()
    finally:
        conn.close()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï BIZFIN PRO SEO PIPELINE V2")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    db_path = create_sqlite_database()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    analysis_result = test_competitor_analyzer()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
    test_database_operations()
    
    print("\n" + "=" * 60)
    print("üéâ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 60)
    
    if analysis_result:
        print("‚úÖ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç")
    else:
        print("‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")
    
    print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö SQLite —Ä–∞–±–æ—Ç–∞–µ—Ç")
    print("‚úÖ –û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è")
    
    print(f"\nüìÅ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {db_path}")
    print("üöÄ –ì–æ—Ç–æ–≤–æ –∫ –∑–∞–ø—É—Å–∫—É –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞!")

if __name__ == "__main__":
    main()


